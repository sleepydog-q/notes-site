<!doctype html><html lang=en-us><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><title>ML Inference / Infra Interview Prep | sleepydog</title><meta name=description content="Personal blog and knowledge base"><style>:root{--bg-color:#ffffff;--text-color:#2c3e50;--link-color:#3498db;--border-color:#e1e4e8;--code-bg:#f6f8fa;--header-bg:#ffffff;--card-bg:#ffffff;--shadow:0 2px 4px rgba(0,0,0,0.1)}@media(prefers-color-scheme:dark){:root{--bg-color:#1e1e1e;--text-color:#e4e4e4;--link-color:#58a6ff;--border-color:#30363d;--code-bg:#161b22;--header-bg:#161b22;--card-bg:#0d1117;--shadow:0 2px 8px rgba(0,0,0,0.4)}a{color:#58a6ff}a:hover{color:#79c0ff}.category-tag{color:#aaa;background:#2a2a2a;border-color:#444}.category-tag:hover{color:#58a6ff;border-color:#58a6ff}.tag{color:#888}}*{margin:0;padding:0;box-sizing:border-box}body{font-family:-apple-system,BlinkMacSystemFont,segoe ui,Roboto,Oxygen,Ubuntu,Cantarell,sans-serif;line-height:1.7;color:var(--text-color);background:var(--bg-color);transition:background .3s,color .3s}header{background:var(--header-bg);border-bottom:1px solid var(--border-color);padding:1rem 0;position:sticky;top:0;z-index:1000}.container{max-width:1400px;margin:0 auto;padding:0 2rem}.header-content{display:flex;justify-content:space-between;align-items:center}.site-title{font-size:1.5rem;font-weight:600;color:var(--text-color);text-decoration:none}nav ul{list-style:none;display:flex;gap:1.5rem}nav a{color:var(--text-color);text-decoration:none;font-size:.95rem}nav a:hover{color:var(--link-color)}main{min-height:70vh;padding:1.5rem 0}article{margin-bottom:2rem}h1,h2,h3,h4,h5,h6{margin:1.5rem 0 1rem;line-height:1.3;font-weight:600;scroll-margin-top:5rem}h1{font-size:2rem;margin-top:0}h2{font-size:1.5rem}h3{font-size:1.25rem}a{color:#06c;text-decoration:none}a:hover{color:#003d7a;text-decoration:underline}p{margin:1rem 0}.post-meta{color:#6c757d;font-size:.85rem;margin:.25rem 0 .5rem;line-height:1.5}.post-meta time{margin-right:1rem}.post-footer-meta{margin-top:2rem;padding-top:1rem;border-top:1px solid var(--border-color);text-align:right}.post-footer-meta .lastmod{color:#888;font-size:.85rem;font-style:italic}.comments-section{margin-top:3rem;padding-top:2rem;border-top:1px solid var(--border-color)}.post-list{list-style:none}.post-item{padding:.75rem 0;margin-bottom:1rem;border-bottom:1px solid var(--border-color)}.post-item:hover{background:0 0}.post-item h2{margin:0 0 .2rem;font-size:1.2rem;font-weight:500}.post-item h2 a{color:var(--text-color)}.categories{display:inline;margin-right:.5rem}.category-tag{font-size:.8rem;color:#555;text-decoration:none;margin-right:.5rem;padding:.1rem .4rem;border:1px solid #ccc;border-radius:3px;background:#f8f8f8}.category-tag:hover{color:#06c;border-color:#06c;text-decoration:none}.tag{font-size:.8rem;color:#999;margin-right:.75rem}.tag::before{content:"#"}.tags{display:inline}footer{background:var(--header-bg);border-top:1px solid var(--border-color);padding:1.5rem 0;margin-top:3rem;text-align:center;color:#6c757d;font-size:.9rem}code{background:var(--code-bg);padding:.1rem .3rem;font-size:.9em}pre{background:var(--code-bg);padding:1rem;border-left:3px solid var(--border-color);overflow-x:auto;margin:1.5rem 0;border:1px solid var(--border-color);border-radius:4px;line-height:1.5}pre code{background:0 0;padding:0;border:none;font-family:consolas,monaco,courier new,monospace;font-size:.9rem}article ul,article ol{margin:1rem 0;padding-left:2rem}article ul{list-style-type:disc}article ol{list-style-type:decimal}article li{margin:.5rem 0;line-height:1.6}article li>ul,article li>ol{margin:.5rem 0}article li>p{margin:.25rem 0}article strong{font-weight:600}article em{font-style:italic}.post-container{display:flex;gap:2rem;max-width:1400px;margin:0 auto}.post-content{flex:1;min-width:0;max-width:1100px}.toc-sidebar{width:350px;flex-shrink:0}.toc-sticky{position:sticky;top:5rem;max-height:calc(100vh - 6rem);overflow-y:auto;padding:1rem;border-left:2px solid var(--border-color)}.toc-sidebar h3{font-size:1rem;margin:0 0 1rem;color:var(--text-color);font-weight:600}.toc-sidebar nav ul{list-style:none;padding-left:0;margin:0;display:block!important}.toc-sidebar nav ul ul{padding-left:1rem;margin-top:.25rem;display:block!important}.toc-sidebar nav li{margin:.5rem 0;display:list-item!important}.toc-sidebar nav a{color:#6c757d;text-decoration:none;font-size:.9rem;display:block;line-height:1.4}.toc-sidebar nav a:hover{color:var(--link-color)}#TableOfContents ul{display:block!important}#TableOfContents li{display:list-item!important}@media(max-width:768px){.container{padding:0 1rem}.header-content{flex-direction:column;gap:1rem}nav ul{gap:1rem}h1{font-size:2rem}article,.post-item{padding:1rem}.post-container{flex-direction:column;gap:1.5rem}.toc-sidebar{width:100%;order:-1}.toc-sticky{position:static;max-height:none;border-left:none;border-top:2px solid var(--border-color);padding:1rem 0}.post-content{max-width:none}}.highlight{background-color:#f6f8fa;border-radius:6px;margin:1.5rem 0;overflow:hidden}.bg{background-color:#fff}.chroma{background-color:#f6f8fa}.chroma .err{color:#f6f8fa;background-color:#82071e}.chroma .lnlinks{outline:none;text-decoration:none;color:inherit}.chroma .lntd{vertical-align:top;padding:0;margin:0;border:0}.chroma .lntd:first-child{padding-right:.8em}.chroma .lntable{border-spacing:0;padding:1rem;margin:0;border:0;width:100%}.chroma .hl{background-color:#e5e5e5}.chroma .lnt{white-space:pre;-webkit-user-select:none;user-select:none;color:#57606a;display:block}.chroma .ln{white-space:pre;-webkit-user-select:none;user-select:none;color:#57606a}.toc-sidebar li{display:block!important}.chroma .k{color:#cf222e}.chroma .kc{color:#cf222e}.chroma .kd{color:#cf222e}.chroma .kn{color:#cf222e}.chroma .kp{color:#cf222e}.chroma .kr{color:#cf222e}.chroma .kt{color:#cf222e}.chroma .na{color:#1f2328}.chroma .nc{color:#1f2328}.chroma .no{color:#0550ae}.chroma .nd{color:#0550ae}.chroma .ni{color:#6639ba}.chroma .nl{color:#900;font-weight:700}.chroma .nn{color:#24292e}.chroma .nx{color:#1f2328}.chroma .nt{color:#0550ae}.chroma .nb{color:#6639ba}.chroma .bp{color:#6a737d}.chroma .nv{color:#953800}.chroma .vc{color:#953800}.chroma .vg{color:#953800}.chroma .vi{color:#953800}.chroma .vm{color:#953800}.chroma .nf{color:#6639ba}.chroma .fm{color:#6639ba}.chroma .s{color:#0a3069}.chroma .sa{color:#0a3069}.chroma .sb{color:#0a3069}.chroma .sc{color:#0a3069}.chroma .dl{color:#0a3069}.chroma .sd{color:#0a3069}.chroma .s2{color:#0a3069}.chroma .se{color:#0a3069}.chroma .sh{color:#0a3069}.chroma .si{color:#0a3069}.chroma .sx{color:#0a3069}.chroma .sr{color:#0a3069}.chroma .s1{color:#0a3069}.chroma .ss{color:#032f62}.chroma .m{color:#0550ae}.chroma .mb{color:#0550ae}.chroma .mf{color:#0550ae}.chroma .mh{color:#0550ae}.chroma .mi{color:#0550ae}.chroma .il{color:#0550ae}.chroma .mo{color:#0550ae}.chroma .o{color:#0550ae}.chroma .ow{color:#0550ae}.chroma .p{color:#1f2328}.chroma .c{color:#57606a}.chroma .ch{color:#57606a}.chroma .cm{color:#57606a}.chroma .c1{color:#57606a}.chroma .cs{color:#57606a}.chroma .cp{color:#57606a}.chroma .cpf{color:#57606a}.chroma .gd{color:#82071e;background-color:#ffebe9}.chroma .ge{color:#1f2328}.chroma .gi{color:#116329;background-color:#dafbe1}.chroma .go{color:#1f2328}.chroma .gl{text-decoration:underline}.chroma .w{color:#fff}</style></head><body><header><div class=container><div class=header-content><a href=/notes-site/ class=site-title>sleepydog</a><nav><ul><li><a href=/notes-site/>Home</a></li><li><a href=/notes-site/posts/>Posts</a></li><li><a href=/notes-site/categories/>Categories</a></li></ul></nav></div></div></header><main><div class=container><div class=post-container><aside class=toc-sidebar><div class=toc-sticky><h3>Table of Contents</h3><nav id=TableOfContents><ul><li><a href=#llm-decoder-only-transformer><strong>LLM (Decoder-only Transformer)</strong></a><ul><li><a href=#1-prefill-vs-decode><strong>1. Prefill vs. Decode</strong></a></li><li><a href=#2-kv-cache><strong>2. KV cache</strong></a></li><li><a href=#3-continuous-batching><strong>3. Continuous batching</strong></a></li><li><a href=#4-attention--compute-optimizations><strong>4. Attention & Compute Optimizations</strong></a></li><li><a href=#5-model-compression><strong>5. Model Compression</strong></a></li><li><a href=#6-optimizations-for-long-context-kv><strong>6. Optimizations for Long-Context KV</strong></a></li><li><a href=#7-peft-parameter-efficient-fine-tuning><strong>7. PEFT (Parameter-Efficient Fine-Tuning)</strong></a></li><li><a href=#8-parallelism><strong>8. Parallelism</strong></a></li><li><a href=#communication-collectives><strong>Communication Collectives</strong></a></li><li><a href=#9-more-topics-to-cover><strong>9. More topics to cover…</strong></a></li></ul></li></ul></nav></div></aside><article class=post-content><h1>ML Inference / Infra Interview Prep</h1><div class=post-meta><time>October 24, 2025</time><div class=categories><a href=/notes-site/categories/job-hunting/ class=category-tag>Job Hunting</a></div><div class=tags><span class=tag>ml-inference</span>
<span class=tag>interview</span>
<span class=tag>infrastructure</span></div></div><h2 id=llm-decoder-only-transformer><strong>LLM (Decoder-only Transformer)</strong></h2><h3 id=1-prefill-vs-decode><strong>1. Prefill vs. Decode</strong></h3><ul><li>What is prefill and decode</li><li>What&rsquo;s different in terms of compute vs memory</li></ul><h3 id=2-kv-cache><strong>2. KV cache</strong></h3><ul><li>What is KV cache</li><li>Why can we cache KV</li><li>What is the dimension of query Q at decoding and why</li><li>PagedAttention</li><li>&mldr;</li></ul><h3 id=3-continuous-batching><strong>3. Continuous batching</strong></h3><ul><li>What, why, and how</li></ul><h3 id=4-attention--compute-optimizations><strong>4. Attention & Compute Optimizations</strong></h3><ul><li>FlashAttention (v1–v3)</li><li>Fused kernels, memory tiling</li><li>Efficient softmax / normalization</li></ul><h3 id=5-model-compression><strong>5. Model Compression</strong></h3><ul><li>Quantization</li><li>Sparsity/Pruning</li><li>Low-Rank / Tensor Factorization</li><li>&mldr;</li></ul><h3 id=6-optimizations-for-long-context-kv><strong>6. Optimizations for Long-Context KV</strong></h3><ul><li>Windowed Attention (Local Attention)</li><li>Advanced KV compression techniques</li><li>&mldr;</li></ul><h3 id=7-peft-parameter-efficient-fine-tuning><strong>7. PEFT (Parameter-Efficient Fine-Tuning)</strong></h3><ul><li>LoRA, QLoRA</li><li>How does PEFT techniques change memory and compute requirements/complexity</li><li>&mldr;</li></ul><h3 id=8-parallelism><strong>8. Parallelism</strong></h3><ul><li>Data Paralellism</li><li>Tensor Paralellism</li><li>Pipeline Parallelism</li><li>Embedding Table Sharding</li><li>MegatronLM & DeepSpeed (for training)</li><li>&mldr;</li></ul><h3 id=communication-collectives><strong>Communication Collectives</strong></h3><ul><li>Reduce</li><li>Gather</li><li>Broadcast</li><li>Scatter</li><li>&mldr;</li></ul><h3 id=9-more-topics-to-cover><strong>9. More topics to cover&mldr;</strong></h3><div class=post-footer-meta><span class=lastmod>Updated: October 24, 2025</span></div><div class=comments-section><script src=https://giscus.app/client.js data-repo=sleepydog-q/notes-site data-repo-id=R_kgDOQIjY8w data-category=General data-category-id=DIC_kwDOQIjY884CxCKj data-mapping=pathname data-strict=0 data-reactions-enabled=1 data-emit-metadata=0 data-input-position=bottom data-theme=preferred_color_scheme data-lang=en crossorigin=anonymous async></script></div></article></div></div></main><footer><div class=container><p>&copy; 2025 sleepydog | Personal blog and knowledge base</p><p><a href=https://github.com/sleepydog-q target=_blank>GitHub</a></p></div></footer></body></html>